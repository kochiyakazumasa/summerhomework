import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from text_analyzer import TextAnalyzer
from database_manager import DatabaseManager
from url_analyzer import URLAnalyzer
import os
import base64

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 0.5rem 0;
    }
    .stProgress > div > div > div > div {
        background-color: #667eea;
    }
    .stButton > button {
        background: linear-gradient(45deg, #667eea, #764ba2);
        border: none;
        border-radius: 25px;
        padding: 12px 30px;
        font-weight: 600;
        color: white;
    }
    .stButton > button:hover {
        background: linear-gradient(45deg, #5a6fd8, #6a4190);
        transform: translateY(-2px);
    }
</style>
""", unsafe_allow_html=True)

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
@st.cache_resource
def init_analyzer():
    return TextAnalyzer()

@st.cache_resource
def init_database():
    return DatabaseManager()

@st.cache_resource
def init_url_analyzer():
    return URLAnalyzer()

analyzer = init_analyzer()
db_manager = init_database()
url_analyzer = init_url_analyzer()

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
def get_download_link(data, filename, file_type):
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
    if file_type == "csv":
        csv = data.to_csv(index=False, encoding='utf-8-sig')
        b64 = base64.b64encode(csv.encode()).decode()
        href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">ğŸ“¥ {filename}ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
    elif file_type == "txt":
        b64 = base64.b64encode(data.encode('utf-8')).decode()
        href = f'<a href="data:file/txt;base64,{b64}" download="{filename}">ğŸ“¥ {filename}ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
    return href

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
def main():
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒšãƒ¼ã‚¸é¸æŠ
    st.sidebar.title("ğŸ“Š ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª")
    page = st.sidebar.selectbox(
        "ãƒšãƒ¼ã‚¸ã‚’é¸æŠ",
        ["ğŸ  ãƒ›ãƒ¼ãƒ ", "ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ", "ğŸ“š åˆ†æå±¥æ­´", "ğŸ“Š çµ±è¨ˆæƒ…å ±", "ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†"]
    )
    
    if page == "ğŸ  ãƒ›ãƒ¼ãƒ ":
        show_home_page()
    elif page == "ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ":
        show_analysis_page()
    elif page == "ğŸ“š åˆ†æå±¥æ­´":
        show_history_page()
    elif page == "ğŸ“Š çµ±è¨ˆæƒ…å ±":
        show_statistics_page()
    elif page == "ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†":
        show_data_management_page()

def show_home_page():
    """ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸"""
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“Š ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª</h1>
        <p>ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€è©³ç´°ãªåˆ†æçµæœã‚’å–å¾—ã—ã¾ã—ã‚‡ã†</p>
    </div>
    """, unsafe_allow_html=True)
    
    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
    stats = db_manager.get_statistics()
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç·åˆ†ææ•°", f"{stats['total_analyses']:,}")
    with col2:
        st.metric("å¹³å‡ãƒ†ã‚­ã‚¹ãƒˆé•·", f"{stats['avg_text_length']:,} æ–‡å­—")
    with col3:
        st.metric("æœ€ã‚‚ä¸€èˆ¬çš„ãªè¨€èª", stats['most_common_language'])
    with col4:
        st.metric("å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢", f"{stats['avg_sentiment_score']:.1f}%")
    
    st.markdown("---")
    
    # ã‚¯ã‚¤ãƒƒã‚¯åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯åˆ†æ")
    st.write("ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã‹ã‚‰ç›´æ¥ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚")
    
    # å…¥åŠ›æ–¹æ³•é¸æŠ
    input_method = st.radio(
        "å…¥åŠ›æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„",
        ["ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›", "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "URLåˆ†æ"],
        horizontal=True
    )
    
    # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
    if input_method == "ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›":
        text_input = st.text_area(
            "åˆ†æã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            height=150,
            placeholder="ã“ã“ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."
        )
        
        col1, col2 = st.columns([1, 1])
        with col1:
            if st.button("ğŸ” ã‚¯ã‚¤ãƒƒã‚¯åˆ†æ", type="primary"):
                if text_input.strip():
                    with st.spinner("ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æä¸­..."):
                        results = analyzer.analyze_text(text_input)
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                        analysis_id = db_manager.save_analysis_result(
                            text_input, results
                        )
                        st.session_state['home_results'] = results
                        st.session_state['home_analysis_id'] = analysis_id
                        st.success(f"âœ… åˆ†æå®Œäº†ï¼åˆ†æID: {analysis_id}")
                else:
                    st.error("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        with col2:
            if st.button("ğŸ“ è©³ç´°åˆ†æãƒšãƒ¼ã‚¸ã¸"):
                st.switch_page("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    elif input_method == "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        uploaded_file = st.file_uploader(
            "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['txt'],
            help="ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.txtï¼‰ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™"
        )
        
        if uploaded_file is not None:
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("ğŸ“ ã‚¯ã‚¤ãƒƒã‚¯åˆ†æ", type="primary"):
                    with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æä¸­..."):
                        text_content = uploaded_file.read().decode('utf-8')
                        if text_content.strip():
                            results = analyzer.analyze_text(text_content)
                            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                            analysis_id = db_manager.save_analysis_result(
                                text_content, results, 
                                uploaded_file.name, len(text_content)
                            )
                            st.session_state['home_results'] = results
                            st.session_state['home_analysis_id'] = analysis_id
                            st.success(f"âœ… åˆ†æå®Œäº†ï¼åˆ†æID: {analysis_id}")
                        else:
                            st.error("ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")
            
            with col2:
                if st.button("ğŸ“ è©³ç´°åˆ†æãƒšãƒ¼ã‚¸ã¸"):
                    st.switch_page("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ")
    
    # URLåˆ†æ
    else:
        url_input = st.text_input(
            "åˆ†æã—ãŸã„Webãƒšãƒ¼ã‚¸ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="https://example.com ã¾ãŸã¯ example.com"
        )
        
        if url_input:
            # URLã®åŸºæœ¬æƒ…å ±ã‚’è¡¨ç¤º
            page_info = url_analyzer.get_page_info(url_input)
            
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«:** {page_info['title']}")
                st.write(f"**æ–‡å­—æ•°:** {page_info['char_count']:,}")
            
            with col2:
                if page_info['description']:
                    st.write(f"**èª¬æ˜:** {page_info['description'][:100]}...")
                else:
                    st.write("**èª¬æ˜:** ãªã—")
            
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("ğŸŒ URLåˆ†æ", type="primary"):
                    success, result = url_analyzer.extract_text_from_url(url_input)
                    if success:
                        with st.spinner("ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æä¸­..."):
                            results = analyzer.analyze_text(result)
                            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                            analysis_id = db_manager.save_analysis_result(
                                result, results, 
                                f"URL: {url_input}", len(result)
                            )
                            st.session_state['home_results'] = results
                            st.session_state['home_analysis_id'] = analysis_id
                            st.success(f"âœ… åˆ†æå®Œäº†ï¼åˆ†æID: {analysis_id}")
                    else:
                        st.error(f"URLåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {result}")
            
            with col2:
                if st.button("ğŸ“ è©³ç´°åˆ†æãƒšãƒ¼ã‚¸ã¸"):
                    st.switch_page("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ")
    
    # ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã§ã®çµæœè¡¨ç¤ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
    if 'home_results' in st.session_state:
        st.markdown("---")
        st.subheader("ğŸ“Š åˆ†æçµæœï¼ˆç°¡æ˜“ç‰ˆï¼‰")
        
        results = st.session_state['home_results']
        
        # åŸºæœ¬çµ±è¨ˆã®è¡¨ç¤º
        basic_stats = results['basic_stats']
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("æ–‡å­—æ•°", f"{basic_stats['character_count']:,}")
            st.metric("å˜èªæ•°", f"{basic_stats['word_count']:,}")
        
        with col2:
            st.metric("æ–‡ã®æ•°", f"{basic_stats['sentence_count']:,}")
            st.metric("æ®µè½æ•°", f"{basic_stats['paragraph_count']:,}")
        
        with col3:
            st.metric("å¹³å‡å˜èªæ•°/æ–‡", f"{basic_stats['average_words_per_sentence']:.1f}")
            st.metric("å¹³å‡æ–‡å­—æ•°/å˜èª", f"{basic_stats['average_characters_per_word']:.1f}")
        
        # è¨€èªã¨æ„Ÿæƒ…ã®è¡¨ç¤º
        lang = results['language_detection']
        sentiment = results['sentiment_analysis']
        
        col1, col2 = st.columns(2)
        with col1:
            st.info(f"ğŸŒ **æ¤œå‡ºã•ã‚ŒãŸè¨€èª:** {lang['language_name']} ({lang['language_code']})")
        
        with col2:
            sentiment_color = "green" if sentiment['sentiment'] == 'ãƒã‚¸ãƒ†ã‚£ãƒ–' else "red" if sentiment['sentiment'] == 'ãƒã‚¬ãƒ†ã‚£ãƒ–' else "orange"
            st.metric("æ„Ÿæƒ…", sentiment['sentiment'], delta=f"{sentiment['polarity_percentage']}%")
        
        # è©³ç´°çµæœã¸ã®ãƒªãƒ³ã‚¯
        st.markdown("---")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“Š è©³ç´°çµæœã‚’è¡¨ç¤º", type="secondary"):
                st.switch_page("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ")
        
        with col2:
            if st.button("ğŸ“š åˆ†æå±¥æ­´ã‚’ç¢ºèª", type="secondary"):
                st.switch_page("ğŸ“š åˆ†æå±¥æ­´")
    
    st.markdown("---")
    
    # æ©Ÿèƒ½ç´¹ä»‹
    st.subheader("ğŸ¯ ä¸»ãªæ©Ÿèƒ½")
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ**
        - åŸºæœ¬çµ±è¨ˆï¼ˆæ–‡å­—æ•°ã€å˜èªæ•°ã€æ–‡ã®æ•°ï¼‰
        - è¨€èªæ¤œå‡º
        - æ„Ÿæƒ…åˆ†æ
        - å¯èª­æ€§åˆ†æ
        - å˜èªé »åº¦åˆ†æ
        - æ–‡ã®åˆ†æ
        - æ–‡å­—åˆ†æ
        """)
    
    with col2:
        st.markdown("""
        **ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†**
        - åˆ†æçµæœã®è‡ªå‹•ä¿å­˜
        - åˆ†æå±¥æ­´ã®é–²è¦§
        - CSV/TXTå½¢å¼ã§ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        - çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
        - ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤æ©Ÿèƒ½
        """)
    
    # æœ€è¿‘ã®åˆ†æå±¥æ­´ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    st.markdown("---")
    st.subheader("ğŸ“š æœ€è¿‘ã®åˆ†æå±¥æ­´")
    
    df = db_manager.get_all_analyses()
    if not df.empty:
        # æœ€æ–°5ä»¶ã‚’è¡¨ç¤º
        recent_df = df.head(5)[['id', 'timestamp', 'file_name', 'text_length']].copy()
        recent_df['file_name'] = recent_df['file_name'].fillna('ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›')
        recent_df.columns = ['ID', 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—', 'ãƒ•ã‚¡ã‚¤ãƒ«å', 'æ–‡å­—æ•°']
        
        st.dataframe(
            recent_df,
            hide_index=True,
            use_container_width=True
        )
        
        if st.button("ğŸ“š å…¨å±¥æ­´ã‚’è¡¨ç¤º"):
            st.switch_page("ğŸ“š åˆ†æå±¥æ­´")
    else:
        st.info("ã¾ã åˆ†æå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")

def show_analysis_page():
    """ãƒ†ã‚­ã‚¹ãƒˆåˆ†æãƒšãƒ¼ã‚¸"""
    st.header("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ")
    
    # å…¥åŠ›æ–¹æ³•é¸æŠ
    input_method = st.radio(
        "å…¥åŠ›æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„",
        ["ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›", "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "URLåˆ†æ"],
        horizontal=True
    )
    
    # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
    if input_method == "ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›":
        text_input = st.text_area(
            "åˆ†æã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            height=200,
            placeholder="ã“ã“ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."
        )
        
        col1, col2 = st.columns([1, 1])
        with col1:
            if st.button("ğŸ” åˆ†æé–‹å§‹", type="primary"):
                if text_input.strip():
                    with st.spinner("ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æä¸­..."):
                        results = analyzer.analyze_text(text_input)
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                        analysis_id = db_manager.save_analysis_result(
                            text_input, results
                        )
                        st.session_state['current_results'] = results
                        st.session_state['current_analysis_id'] = analysis_id
                        st.success(f"âœ… åˆ†æå®Œäº†ï¼åˆ†æID: {analysis_id}")
                else:
                    st.error("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        with col2:
            if st.button("ğŸ’¾ åˆ†æçµæœã‚’ä¿å­˜"):
                if 'current_results' in st.session_state:
                    st.success("åˆ†æçµæœãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
                else:
                    st.warning("å…ˆã«ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã¦ãã ã•ã„")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    elif input_method == "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        uploaded_file = st.file_uploader(
            "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['txt'],
            help="ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.txtï¼‰ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™"
        )
        
        if uploaded_file is not None:
            if st.button("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ", type="primary"):
                with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æä¸­..."):
                    text_content = uploaded_file.read().decode('utf-8')
                    if text_content.strip():
                        results = analyzer.analyze_text(text_content)
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                        analysis_id = db_manager.save_analysis_result(
                            text_content, results, 
                            uploaded_file.name, len(text_content)
                        )
                        st.session_state['current_results'] = results
                        st.session_state['current_analysis_id'] = analysis_id
                        st.success(f"âœ… åˆ†æå®Œäº†ï¼åˆ†æID: {analysis_id}")
                    else:
                        st.error("ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")
    
    # URLåˆ†æ
    else:
        url_input = st.text_input(
            "åˆ†æã—ãŸã„Webãƒšãƒ¼ã‚¸ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="https://example.com ã¾ãŸã¯ example.com"
        )
        
        if url_input:
            # URLã®åŸºæœ¬æƒ…å ±ã‚’è¡¨ç¤º
            page_info = url_analyzer.get_page_info(url_input)
            
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«:** {page_info['title']}")
                st.write(f"**æ–‡å­—æ•°:** {page_info['char_count']:,}")
            
            with col2:
                if page_info['description']:
                    st.write(f"**èª¬æ˜:** {page_info['description'][:100]}...")
                else:
                    st.write("**èª¬æ˜:** ãªã—")
            
            if st.button("ğŸŒ URLåˆ†æ", type="primary"):
                success, result = url_analyzer.extract_text_from_url(url_input)
                if success:
                    with st.spinner("ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æä¸­..."):
                        results = analyzer.analyze_text(result)
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                        analysis_id = db_manager.save_analysis_result(
                            result, results, 
                            f"URL: {url_input}", len(result)
                        )
                        st.session_state['current_results'] = results
                        st.session_state['current_analysis_id'] = analysis_id
                        st.success(f"âœ… åˆ†æå®Œäº†ï¼åˆ†æID: {analysis_id}")
                else:
                    st.error(f"URLåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {result}")
    
    # çµæœè¡¨ç¤º
    if 'current_results' in st.session_state:
        display_results(st.session_state['current_results'])

def show_history_page():
    """åˆ†æå±¥æ­´ãƒšãƒ¼ã‚¸"""
    st.header("ğŸ“š åˆ†æå±¥æ­´")
    
    # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    df = db_manager.get_all_analyses()
    
    if df.empty:
        st.info("ã¾ã åˆ†æå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
        return
    
    # æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    col1, col2 = st.columns(2)
    with col1:
        search_term = st.text_input("æ¤œç´¢ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ï¼‰")
    with col2:
        language_filter = st.selectbox(
            "è¨€èªã§ãƒ•ã‚£ãƒ«ã‚¿",
            ["ã™ã¹ã¦"] + list(df['language_detection'].apply(
                lambda x: x.get('language_name', 'ä¸æ˜') if x else 'ä¸æ˜'
            ).unique())
        )
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if search_term:
        df = df[df['text_content'].str.contains(search_term, case=False, na=False) |
                df['file_name'].str.contains(search_term, case=False, na=False)]
    
    if language_filter != "ã™ã¹ã¦":
        df = df[df['language_detection'].apply(
            lambda x: x.get('language_name', 'ä¸æ˜') if x else 'ä¸æ˜'
        ) == language_filter]
    
    # å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
    st.subheader(f"åˆ†æå±¥æ­´ ({len(df)}ä»¶)")
    
    # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    display_df = df[['id', 'timestamp', 'file_name', 'text_length']].copy()
    display_df['file_name'] = display_df['file_name'].fillna('ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›')
    display_df.columns = ['ID', 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—', 'ãƒ•ã‚¡ã‚¤ãƒ«å', 'æ–‡å­—æ•°']
    
    # é¸æŠå¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«
    selected_indices = st.data_editor(
        display_df,
        hide_index=True,
        use_container_width=True
    )
    
    # è©³ç´°è¡¨ç¤º
    if selected_indices:
        selected_id = df.iloc[selected_indices[0]]['id']
        analysis = db_manager.get_analysis_by_id(selected_id)
        
        if analysis:
            st.subheader(f"åˆ†æè©³ç´° (ID: {selected_id})")
            
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—:** {analysis['timestamp']}")
                st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«å:** {analysis['file_name'] or 'ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›'}")
                st.write(f"**æ–‡å­—æ•°:** {analysis['text_length']:,}")
            
            with col2:
                if st.button("ğŸ—‘ï¸ ã“ã®åˆ†æã‚’å‰Šé™¤", type="secondary"):
                    if db_manager.delete_analysis(selected_id):
                        st.success("åˆ†æçµæœã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                        st.rerun()
                    else:
                        st.error("å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã®è¡¨ç¤º
            with st.expander("ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’è¡¨ç¤º"):
                st.text_area("ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹", analysis['text_content'], height=200, disabled=True)
            
            # åˆ†æçµæœã®è¡¨ç¤º
            display_results(analysis)

def show_statistics_page():
    """çµ±è¨ˆæƒ…å ±ãƒšãƒ¼ã‚¸"""
    st.header("ğŸ“Š çµ±è¨ˆæƒ…å ±")
    
    stats = db_manager.get_statistics()
    df = db_manager.get_all_analyses()
    
    if df.empty:
        st.info("ã¾ã åˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # åŸºæœ¬çµ±è¨ˆ
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç·åˆ†ææ•°", f"{stats['total_analyses']:,}")
    with col2:
        st.metric("å¹³å‡ãƒ†ã‚­ã‚¹ãƒˆé•·", f"{stats['avg_text_length']:,} æ–‡å­—")
    with col3:
        st.metric("æœ€ã‚‚ä¸€èˆ¬çš„ãªè¨€èª", stats['most_common_language'])
    with col4:
        st.metric("å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢", f"{stats['avg_sentiment_score']:.1f}%")
    
    st.markdown("---")
    
    # è¨€èªåˆ†å¸ƒ
    st.subheader("ğŸŒ è¨€èªåˆ†å¸ƒ")
    language_counts = df['language_detection'].apply(
        lambda x: x.get('language_name', 'ä¸æ˜') if x else 'ä¸æ˜'
    ).value_counts()
    
    fig = px.pie(
        values=language_counts.values,
        names=language_counts.index,
        title="åˆ†æã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®è¨€èªåˆ†å¸ƒ"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # æ„Ÿæƒ…åˆ†å¸ƒ
    st.subheader("ğŸ’ æ„Ÿæƒ…åˆ†å¸ƒ")
    sentiment_counts = df['sentiment_analysis'].apply(
        lambda x: x.get('sentiment', 'ä¸æ˜') if x else 'ä¸æ˜'
    ).value_counts()
    
    fig = px.bar(
        x=sentiment_counts.index,
        y=sentiment_counts.values,
        title="æ„Ÿæƒ…åˆ†æã®çµæœåˆ†å¸ƒ"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # ãƒ†ã‚­ã‚¹ãƒˆé•·ã®åˆ†å¸ƒ
    st.subheader("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆé•·ã®åˆ†å¸ƒ")
    fig = px.histogram(
        df, x='text_length',
        title="ãƒ†ã‚­ã‚¹ãƒˆé•·ã®åˆ†å¸ƒ",
        labels={'text_length': 'æ–‡å­—æ•°', 'count': 'ä»¶æ•°'}
    )
    st.plotly_chart(fig, use_container_width=True)

def show_data_management_page():
    """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒšãƒ¼ã‚¸"""
    st.header("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
    
    df = db_manager.get_all_analyses()
    
    if df.empty:
        st.info("ã¾ã åˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
    st.subheader("ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ“Š å…¨ãƒ‡ãƒ¼ã‚¿ã‚’CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
            csv_data = db_manager.export_to_csv()
            csv_filename = f"text_analysis_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"
            st.markdown(get_download_link(csv_data, csv_filename, "csv"), unsafe_allow_html=True)
    
    with col2:
        if st.button("ğŸ“„ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’TXTã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
            txt_data = db_manager.export_to_txt()
            txt_filename = f"text_analysis_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.txt"
            st.markdown(get_download_link(txt_data, txt_filename, "txt"), unsafe_allow_html=True)
    
    st.markdown("---")
    
    # ãƒ‡ãƒ¼ã‚¿å‰Šé™¤æ©Ÿèƒ½
    st.subheader("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿å‰Šé™¤")
    
    # é¸æŠå¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«
    display_df = df[['id', 'timestamp', 'file_name', 'text_length']].copy()
    display_df['file_name'] = display_df['file_name'].fillna('ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›')
    display_df.columns = ['ID', 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—', 'ãƒ•ã‚¡ã‚¤ãƒ«å', 'æ–‡å­—æ•°']
    
    selected_indices = st.data_editor(
        display_df,
        hide_index=True,
        use_container_width=True
    )
    
    if selected_indices:
        selected_id = df.iloc[selected_indices[0]]['id']
        st.write(f"é¸æŠã•ã‚ŒãŸåˆ†æID: {selected_id}")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ é¸æŠã—ãŸåˆ†æã‚’å‰Šé™¤", type="secondary"):
                if db_manager.delete_analysis(selected_id):
                    st.success("åˆ†æçµæœã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                    st.rerun()
                else:
                    st.error("å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        with col2:
            if st.button("ğŸ—‘ï¸ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤", type="secondary"):
                if st.checkbox("æœ¬å½“ã«å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ"):
                    # å…¨ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã®å®Ÿè£…
                    st.warning("ã“ã®æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™")

def display_results(results):
    """åˆ†æçµæœã‚’è¡¨ç¤º"""
    st.success("âœ… åˆ†æå®Œäº†ï¼")
    
    # ã‚¿ãƒ–ã§çµæœã‚’è¡¨ç¤º
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "ğŸ“Š åŸºæœ¬çµ±è¨ˆ", "ğŸŒ è¨€èªæ¤œå‡º", "ğŸ’ æ„Ÿæƒ…åˆ†æ", 
        "ğŸ“– å¯èª­æ€§", "ğŸ“ˆ å˜èªé »åº¦", "ğŸ“ æ–‡ã®åˆ†æ", "ğŸ”¤ æ–‡å­—åˆ†æ"
    ])
    
    # åŸºæœ¬çµ±è¨ˆ
    with tab1:
        basic_stats = results['basic_stats']
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("æ–‡å­—æ•°", f"{basic_stats['character_count']:,}")
            st.metric("å˜èªæ•°", f"{basic_stats['word_count']:,}")
        
        with col2:
            st.metric("æ–‡ã®æ•°", f"{basic_stats['sentence_count']:,}")
            st.metric("æ®µè½æ•°", f"{basic_stats['paragraph_count']:,}")
        
        with col3:
            st.metric("å¹³å‡å˜èªæ•°/æ–‡", f"{basic_stats['average_words_per_sentence']:.1f}")
            st.metric("å¹³å‡æ–‡å­—æ•°/å˜èª", f"{basic_stats['average_characters_per_word']:.1f}")
    
    # è¨€èªæ¤œå‡º
    with tab2:
        lang = results['language_detection']
        st.info(f"ğŸŒ æ¤œå‡ºã•ã‚ŒãŸè¨€èª: **{lang['language_name']}** ({lang['language_code']})")
    
    # æ„Ÿæƒ…åˆ†æ
    with tab3:
        sentiment = results['sentiment_analysis']
        
        col1, col2 = st.columns(2)
        
        with col1:
            sentiment_color = "green" if sentiment['sentiment'] == 'ãƒã‚¸ãƒ†ã‚£ãƒ–' else "red" if sentiment['sentiment'] == 'ãƒã‚¬ãƒ†ã‚£ãƒ–' else "orange"
            st.metric("æ„Ÿæƒ…", sentiment['sentiment'], delta=f"{sentiment['polarity_percentage']}%")
            
            # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            st.progress(sentiment['polarity_percentage'] / 100)
            st.caption(f"ãƒã‚¸ãƒ†ã‚£ãƒ–åº¦: {sentiment['polarity_percentage']}%")
        
        with col2:
            st.metric("ä¸»è¦³æ€§", f"{(sentiment['subjectivity'] * 100):.1f}%")
            
            # æ„Ÿæƒ…ã®å††ã‚°ãƒ©ãƒ•
            fig = go.Figure(data=[go.Pie(
                labels=['ãƒã‚¸ãƒ†ã‚£ãƒ–', 'ãƒã‚¬ãƒ†ã‚£ãƒ–', 'ä¸­æ€§'],
                values=[sentiment['polarity_percentage'], 100-sentiment['polarity_percentage'], 0],
                hole=0.3
            )])
            fig.update_layout(title="æ„Ÿæƒ…åˆ†å¸ƒ")
            st.plotly_chart(fig, use_container_width=True)
    
    # å¯èª­æ€§åˆ†æ
    with tab4:
        readability = results['readability_score']
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("Fleschå¯èª­æ€§ã‚¹ã‚³ã‚¢", f"{readability['flesch_score']:.1f}")
            st.metric("éŸ³ç¯€æ•°", f"{readability['syllable_count']:,}")
        
        with col2:
            st.info(f"ğŸ“– å¯èª­æ€§ãƒ¬ãƒ™ãƒ«: **{readability['readability_level']}**")
            
            # å¯èª­æ€§ã‚¹ã‚³ã‚¢ã®ã‚²ãƒ¼ã‚¸
            fig = go.Figure(go.Indicator(
                mode = "gauge+number+delta",
                value = readability['flesch_score'],
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "å¯èª­æ€§ã‚¹ã‚³ã‚¢"},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, 30], 'color': "lightgray"},
                        {'range': [30, 70], 'color': "gray"},
                        {'range': [70, 100], 'color': "lightgreen"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 90
                    }
                }
            ))
            st.plotly_chart(fig, use_container_width=True)
    
    # å˜èªé »åº¦
    with tab5:
        word_freq = results['word_frequency']
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°", f"{word_freq['unique_words']:,}")
            st.metric("åˆ†æå¯¾è±¡å˜èªæ•°", f"{word_freq['total_words_analyzed']:,}")
        
        with col2:
            if word_freq['most_common_words']:
                # ä¸Šä½10å˜èªã®æ£’ã‚°ãƒ©ãƒ•
                top_words = word_freq['most_common_words'][:10]
                words, counts = zip(*top_words)
                
                fig = px.bar(
                    x=words, 
                    y=counts,
                    title="æœ€ã‚‚é »ç¹ã«ä½¿ç”¨ã•ã‚Œã‚‹å˜èªï¼ˆä¸Šä½10ï¼‰",
                    labels={'x': 'å˜èª', 'y': 'å‡ºç¾å›æ•°'}
                )
                fig.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig, use_container_width=True)
    
    # æ–‡ã®åˆ†æ
    with tab6:
        sentence_analysis = results['sentence_analysis']
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("å¹³å‡æ–‡ã®é•·ã•", f"{sentence_analysis['average_sentence_length']:.1f} å˜èª")
        
        with col2:
            st.metric("æœ€çŸ­æ–‡", f"{sentence_analysis['shortest_sentence']} å˜èª")
        
        with col3:
            st.metric("æœ€é•·æ–‡", f"{sentence_analysis['longest_sentence']} å˜èª")
        
        # æ–‡ã®é•·ã•åˆ†å¸ƒã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        if 'sentence_lengths' in sentence_analysis:
            fig = px.histogram(
                x=sentence_analysis['sentence_lengths'],
                title="æ–‡ã®é•·ã•åˆ†å¸ƒ",
                labels={'x': 'æ–‡ã®é•·ã•ï¼ˆå˜èªæ•°ï¼‰', 'y': 'é »åº¦'}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # æ–‡å­—åˆ†æ
    with tab7:
        char_analysis = results['character_analysis']
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("ç·æ–‡å­—æ•°", f"{char_analysis['total_letters']:,}")
            st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯æ–‡å­—æ•°", f"{char_analysis['unique_letters']:,}")
        
        with col2:
            if char_analysis['most_common_letters']:
                # ä¸Šä½10æ–‡å­—ã®æ£’ã‚°ãƒ©ãƒ•
                top_letters = char_analysis['most_common_letters'][:10]
                letters, counts = zip(*top_letters)
                
                fig = px.bar(
                    x=letters, 
                    y=counts,
                    title="æœ€ã‚‚é »ç¹ã«ä½¿ç”¨ã•ã‚Œã‚‹æ–‡å­—ï¼ˆä¸Šä½10ï¼‰",
                    labels={'x': 'æ–‡å­—', 'y': 'å‡ºç¾å›æ•°'}
                )
                st.plotly_chart(fig, use_container_width=True)

if __name__ == "__main__":
    main()
